# ============================================
# AI PROVIDER CONFIGURATION
# ============================================
# Choose your AI provider: 'ollama' | 'openai' | 'huggingface' | 'gemini' | 'anthropic'
AI_PROVIDER=gemini

# OLLAMA (Local Models) - DEFAULT
# No API key needed, runs locally
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:1b

# OPENAI (GPT Models)
# Get API key from: https://platform.openai.com/api-keys
# Free $5 credits for new users
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo

# HUGGING FACE (Free Inference API)
# Get API key from: https://huggingface.co/settings/tokens
# Free: 1000 requests/month
HUGGINGFACE_API_KEY=your_huggingface_api_key_here
HUGGINGFACE_MODEL=microsoft/DialoGPT-medium

# GOOGLE GEMINI (Free Tier)
# Get API key from: https://aistudio.google.com
# Free: 15 requests/minute, 1M tokens/day
GEMINI_API_KEY=AIzaSyDNZlzmF6rtf1iZcTR37iL-kdD6cJmpHgM
GEMINI_MODEL=gemini-1.5-flash

# ANTHROPIC CLAUDE
# Get API key from: https://console.anthropic.com
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-haiku-20240307

# Server Configuration
PORT=3001
NODE_ENV=development

# CORS Configuration
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5173

# Rate Limiting
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100

# Session-based Rate Limiting (per user session)
SESSION_MAX_REQUESTS_PER_HOUR=10
SESSION_MAX_REQUESTS_PER_DAY=50

# Request Caching and Deduplication
REQUEST_CACHE_EXPIRY_MS=300000
STATIC_CACHE_EXPIRY_MS=3600000
EMBEDDING_REQUEST_TIMEOUT_MS=30000
